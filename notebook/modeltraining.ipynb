{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97efab2e",
   "metadata": {},
   "source": [
    "Model Training\n",
    "1.1 Import Data and Required Packages\n",
    "Importing Pandas, Numpy, Matplotlib, Seaborn and Warings Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fdea0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "# Modelling\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.linear_model import LinearRegression, Ridge,Lasso\n",
    "#from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "859f5e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: graphviz in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: matplotlib in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from catboost) (3.10.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from catboost) (2.3.2)\n",
      "Requirement already satisfied: pandas>=0.24 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: scipy in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from catboost) (1.16.1)\n",
      "Requirement already satisfied: plotly in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from catboost) (6.2.0)\n",
      "Requirement already satisfied: six in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from matplotlib->catboost) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from matplotlib->catboost) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from plotly->catboost) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10032097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: numpy in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from xgboost) (2.3.2)\n",
      "Requirement already satisfied: scipy in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from xgboost) (1.16.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dbfa07",
   "metadata": {},
   "source": [
    "Import the CSV Data as Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7c77d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/improved_disease_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcec53",
   "metadata": {},
   "source": [
    "Show Top 5 Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fb71da56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fever</th>\n",
       "      <th>headache</th>\n",
       "      <th>nausea</th>\n",
       "      <th>vomiting</th>\n",
       "      <th>fatigue</th>\n",
       "      <th>joint_pain</th>\n",
       "      <th>skin_rash</th>\n",
       "      <th>cough</th>\n",
       "      <th>weight_loss</th>\n",
       "      <th>yellow_eyes</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Paralysis (brain hemorrhage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paralysis (brain hemorrhage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Paralysis (brain hemorrhage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Paralysis (brain hemorrhage)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Paralysis (brain hemorrhage)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fever  headache  nausea  vomiting  fatigue  joint_pain  skin_rash  cough  \\\n",
       "0      1         0       1         0        1           0          0      1   \n",
       "1      0         0       1         0        0           0          1      1   \n",
       "2      0         0       1         0        1           0          1      1   \n",
       "3      0         0       1         1        1           0          1      1   \n",
       "4      1         0       1         0        1           0          0      0   \n",
       "\n",
       "   weight_loss  yellow_eyes                       disease  \n",
       "0            1            0  Paralysis (brain hemorrhage)  \n",
       "1            0            0  Paralysis (brain hemorrhage)  \n",
       "2            0            0  Paralysis (brain hemorrhage)  \n",
       "3            1            1  Paralysis (brain hemorrhage)  \n",
       "4            1            1  Paralysis (brain hemorrhage)  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23bf0bb",
   "metadata": {},
   "source": [
    "Preparing X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7e4976e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "X = df.drop(columns=['disease'],axis=1)\n",
    "y=df['disease']\n",
    "\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "48c985d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fever', 'headache', 'nausea', 'vomiting', 'fatigue', 'joint_pain',\n",
       "       'skin_rash', 'cough', 'weight_loss', 'yellow_eyes', 'disease'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4773ff90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories in 'fever' variable:      [1 0]\n",
      "Categories in 'headache' variable:   [0 1]\n",
      "Categories in'nausea' variable:    [1 0]\n",
      "Categories in 'vomiting' variable:      [0 1]\n",
      "Categories in 'fatigue' variable:      [1 0]\n",
      "Categories in 'joint_pain' variable:      [0 1]\n",
      "Categories in 'skin_rash' variable:   [0 1]\n",
      "Categories in'cough' variable:    [1 0]\n",
      "Categories in 'weight_loss' variable:      [1 0]\n",
      "Categories in 'yellow_eyes' variable:      [0 1]\n",
      "Categories in 'disease' variable:      ['Paralysis (brain hemorrhage)' 'Hypertension' 'Hepatitis B' 'Impetigo'\n",
      " 'Chronic cholestasis' 'Hepatitis C' 'Typhoid'\n",
      " 'Dimorphic hemorrhoids(piles)'\n",
      " 'Vertigo (Benign paroxysmal Positional Vertigo)' 'Cervical spondylosis'\n",
      " 'Tuberculosis' 'Hyperthyroidism' 'Malaria' 'Gastroenteritis'\n",
      " 'Osteoarthritis' 'Heart attack' 'Dengue' 'Pneumonia'\n",
      " 'Urinary tract infection' 'Hypoglycemia' 'Bronchial Asthma' 'Arthritis'\n",
      " 'Hepatitis D' 'Hypothyroidism' 'Acne' 'GERD' 'Peptic ulcer disease'\n",
      " 'Psoriasis' 'Drug Reaction' 'Diabetes' 'Varicose veins' 'Hepatitis A'\n",
      " 'Hepatitis E' 'Migraine' 'Allergy' 'Jaundice' 'AIDS'\n",
      " 'Alcoholic hepatitis']\n"
     ]
    }
   ],
   "source": [
    "print(\"Categories in 'fever' variable:     \",end=\" \" )\n",
    "print(df['fever'].unique())\n",
    "\n",
    "print(\"Categories in 'headache' variable:  \",end=\" \")\n",
    "print(df['headache'].unique())\n",
    "\n",
    "print(\"Categories in'nausea' variable:   \",end=\" \" )\n",
    "print(df['nausea'].unique())\n",
    "\n",
    "print(\"Categories in 'vomiting' variable:     \",end=\" \" )\n",
    "print(df['vomiting'].unique())\n",
    "\n",
    "print(\"Categories in 'fatigue' variable:     \",end=\" \" )\n",
    "print(df['fatigue'].unique())\n",
    "\n",
    "print(\"Categories in 'joint_pain' variable:     \",end=\" \" )\n",
    "print(df['joint_pain'].unique())\n",
    "\n",
    "print(\"Categories in 'skin_rash' variable:  \",end=\" \")\n",
    "print(df['skin_rash'].unique())\n",
    "\n",
    "print(\"Categories in'cough' variable:   \",end=\" \" )\n",
    "print(df['cough'].unique())\n",
    "\n",
    "print(\"Categories in 'weight_loss' variable:     \",end=\" \" )\n",
    "print(df['weight_loss'].unique())\n",
    "\n",
    "print(\"Categories in 'yellow_eyes' variable:     \",end=\" \" )\n",
    "print(df['yellow_eyes'].unique())\n",
    "\n",
    "print(\"Categories in 'disease' variable:     \",end=\" \" )\n",
    "print(df['disease'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a727d92d",
   "metadata": {},
   "source": [
    "# Create Column Transformer with 3 types of transformers\n",
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "oh_transformer = OneHotEncoder()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "         (\"StandardScaler\", numeric_transformer, num_features),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d20b8",
   "metadata": {},
   "source": [
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2fa81c",
   "metadata": {},
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90fab3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e028b3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 10), (400, 10))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate dataset into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205e1a3",
   "metadata": {},
   "source": [
    "Create an Evaluate Function to give all metrics after model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0ba24ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true, predicted):\n",
    "    acc = accuracy_score(true, predicted)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a1436a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Neighbors classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.4831\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.3300\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.6531\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.3200\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.6531\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.3575\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBclassifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.6531\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.3700\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.6531\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.3500\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.1325\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.1425\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"K-Neighbors classifier\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest classifier\": RandomForestClassifier(),\n",
    "    \"XGBclassifier\": XGBClassifier(), \n",
    "    \"CatBoosting classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost classifier\": AdaBoostClassifier()\n",
    "}\n",
    "model_list = []\n",
    "tr_acc =[]\n",
    "te_acc=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate Train and Test dataset\n",
    "    model_train_acc = evaluate_model(y_train, y_train_pred)\n",
    "\n",
    "    model_test_acc = evaluate_model(y_test, y_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy score for train data: {:.4f}\".format(model_train_acc))\n",
    "  \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Accuracy score for train data: {:.4f}\".format(model_test_acc))\n",
    "\n",
    "    tr_acc.append(model_train_acc)\n",
    "    te_acc.append(model_test_acc)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe07939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>TR_ACC</th>\n",
       "      <th>TE_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBclassifier</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.3700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.3575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoosting classifier</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Neighbors classifier</td>\n",
       "      <td>0.483125</td>\n",
       "      <td>0.3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.653125</td>\n",
       "      <td>0.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost classifier</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.1425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name    TR_ACC  TE_ACC\n",
       "3             XGBclassifier  0.653125  0.3700\n",
       "2  Random Forest classifier  0.653125  0.3575\n",
       "4    CatBoosting classifier  0.653125  0.3500\n",
       "0    K-Neighbors classifier  0.483125  0.3300\n",
       "1             Decision Tree  0.653125  0.3200\n",
       "5       AdaBoost classifier  0.132500  0.1425"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list,tr_acc,te_acc)), columns=['Model Name','TR_ACC','TE_ACC']).sort_values(by=[\"TE_ACC\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76d7c8",
   "metadata": {},
   "source": [
    "In the above case ..there is huge difference between the training accuracy and testing accuracy which means that there is long gap in sampling of data (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42e415db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "sns.countplot(x=y)\n",
    "plt.title(\"Disease Class Distribution Before Resampling\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5a269",
   "metadata": {},
   "source": [
    " visualize class distribution to check for imbalance. We then use RandomOverSampler to balance the dataset by duplicating minority classes and ensuring all diseases have equal samples for fair and effective model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "157b3f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from imbalanced-learn->imblearn) (2.3.2)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
      "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in d:\\projects_practice\\disease_pred\\venv_dis\\lib\\site-packages (from imbalanced-learn->imblearn) (3.6.0)\n",
      "Collecting scikit-learn<2,>=1.3.2 (from imbalanced-learn->imblearn)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.7/11.1 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 18.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 17.4 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-learn, sklearn-compat, imbalanced-learn, imblearn\n",
      "\n",
      "  Attempting uninstall: scikit-learn\n",
      "\n",
      "    Found existing installation: scikit-learn 1.7.1\n",
      "\n",
      "    Uninstalling scikit-learn-1.7.1:\n",
      "\n",
      "      Successfully uninstalled scikit-learn-1.7.1\n",
      "\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   ---------------------------------------- 0/4 [scikit-learn]\n",
      "   -------------------- ------------------- 2/4 [imbalanced-learn]\n",
      "   -------------------- ------------------- 2/4 [imbalanced-learn]\n",
      "   ---------------------------------------- 4/4 [imblearn]\n",
      "\n",
      "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 scikit-learn-1.6.1 sklearn-compat-0.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'D:\\projects_practice\\disease_pred\\venv_dis\\Lib\\site-packages\\~klearn'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "48949280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled Class Distribution:\n",
      " 29    90\n",
      "20    90\n",
      "16    90\n",
      "24    90\n",
      "7     90\n",
      "17    90\n",
      "34    90\n",
      "10    90\n",
      "37    90\n",
      "6     90\n",
      "33    90\n",
      "21    90\n",
      "26    90\n",
      "13    90\n",
      "28    90\n",
      "14    90\n",
      "8     90\n",
      "31    90\n",
      "35    90\n",
      "22    90\n",
      "5     90\n",
      "4     90\n",
      "18    90\n",
      "23    90\n",
      "1     90\n",
      "12    90\n",
      "30    90\n",
      "32    90\n",
      "11    90\n",
      "9     90\n",
      "36    90\n",
      "15    90\n",
      "19    90\n",
      "27    90\n",
      "3     90\n",
      "25    90\n",
      "0     90\n",
      "2     90\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "print(\"Resampled Class Distribution:\\n\", pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "582c7d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: K-Neighbors classifier\n",
      "Scores: [0.5        0.48538012 0.46052632 0.45906433 0.4751462 ]\n",
      "Mean Accuracy: 0.4760\n",
      "==================================================\n",
      "Model: Decision Tree\n",
      "Scores: [0.5497076  0.54385965 0.53216374 0.53654971 0.52631579]\n",
      "Mean Accuracy: 0.5377\n",
      "==================================================\n",
      "Model: Random Forest classifier\n",
      "Scores: [0.5497076  0.54239766 0.54093567 0.53508772 0.52923977]\n",
      "Mean Accuracy: 0.5395\n",
      "==================================================\n",
      "Model: XGBclassifier\n",
      "Scores: [0.55116959 0.55409357 0.53216374 0.53947368 0.53654971]\n",
      "Mean Accuracy: 0.5427\n",
      "==================================================\n",
      "Model: CatBoosting classifier\n",
      "Scores: [0.5628655  0.54385965 0.53947368 0.53947368 0.53654971]\n",
      "Mean Accuracy: 0.5444\n",
      "==================================================\n",
      "Model: AdaBoost classifier\n",
      "Scores: [0.10380117 0.12426901 0.09795322 0.11403509 0.08040936]\n",
      "Mean Accuracy: 0.1041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold,cross_val_score\n",
    "#X_resampled = X_resampled.fillna(0)\n",
    "X_resampled = np.nan_to_num(X_resampled, nan=0)\n",
    "\n",
    "if len(y_resampled.shape) > 1:\n",
    "    y_resampled = y_resampled.values.ravel()\n",
    "\n",
    "models = {\n",
    "    \"K-Neighbors classifier\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest classifier\": RandomForestClassifier(),\n",
    "    \"XGBclassifier\": XGBClassifier(), \n",
    "    \"CatBoosting classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost classifier\": AdaBoostClassifier()\n",
    "}\n",
    "\n",
    "cv_scoring = 'accuracy'  # you can also use 'f1_weighted', 'roc_auc_ovr' for multi-class\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    try:\n",
    "        scores = cross_val_score(\n",
    "            model,\n",
    "            X_resampled,\n",
    "            y_resampled,\n",
    "            cv=stratified_kfold,\n",
    "            scoring=cv_scoring,\n",
    "            n_jobs=-1,\n",
    "            error_score='raise' \n",
    "        )\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Scores: {scores}\")\n",
    "        print(f\"Mean Accuracy: {scores.mean():.4f}\")\n",
    "    except Exception as e:\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"Model: {model_name} failed with error:\")\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6102990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2736, 10), (684, 10))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_samp_train, X_samp_test, y_samp_train, y_samp_test = train_test_split(X_resampled, y_resampled,test_size=0.2,random_state=42)\n",
    "X_samp_train.shape, X_samp_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f09bcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Neighbors classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.6217\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.4664\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.7065\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.5219\n",
      "===================================\n",
      "\n",
      "\n",
      "Random Forest classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.7065\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.5307\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBclassifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.7061\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.5395\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.7065\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.5336\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost classifier\n",
      "Model performance for Training set\n",
      "- Accuracy score for train data: 0.1064\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy score for train data: 0.0936\n",
      "===================================\n",
      "\n",
      "\n",
      "[array([ 0,  1, 25, 17,  9, 28, 10, 17, 33, 18,  1,  6,  2, 19, 27,  8, 15,\n",
      "       35, 34,  2, 33, 35, 11, 32, 36, 25, 33,  0, 19, 32,  2, 27,  1, 28,\n",
      "        4,  5, 20, 25, 30, 17, 33, 14, 37,  2, 31, 18,  8, 23, 30,  8, 14,\n",
      "       18, 17, 22,  4, 26,  8, 30, 19, 25,  4, 32, 13, 37, 12,  4,  3, 16,\n",
      "       13, 31, 22, 15, 29, 25, 21, 26,  7, 31, 27, 36, 17, 27, 23, 20,  8,\n",
      "       15, 29, 12, 34, 32,  8, 30, 18, 25, 21, 25,  0, 15, 27, 19, 29, 18,\n",
      "        9,  4, 24, 27, 32, 27,  3,  7, 14,  8, 12, 11,  8, 27, 21, 26, 10,\n",
      "       27,  0, 18, 13, 15,  1,  3, 13, 14,  1, 29, 15, 10, 17,  8, 24, 35,\n",
      "       30, 29, 29, 30, 34, 25, 12, 33,  3, 18, 12, 16, 32, 18, 29, 10, 37,\n",
      "       29, 18,  0, 27,  4, 12,  3, 23, 31,  2,  8,  3, 35,  9, 20, 36, 31,\n",
      "        6, 12,  1,  1,  6, 29,  4, 30, 10, 33, 23,  9,  2, 30, 33, 32,  9,\n",
      "       29, 18, 13,  0,  4, 36, 10,  9, 13,  2,  1, 18,  4, 28,  1, 15, 26,\n",
      "       14, 24, 22, 32, 21, 15,  0, 18,  0,  7, 15,  1, 13, 14, 33, 37,  3,\n",
      "       14, 28, 15, 10, 36, 20,  1, 22,  9, 21,  4, 30, 13,  9, 13,  3, 32,\n",
      "        7, 24, 35, 18,  1, 33,  5, 18,  9, 34, 11,  7,  1, 29,  6, 25,  4,\n",
      "       32, 13,  0,  4,  1, 33, 19,  6,  9, 10, 24,  6,  0, 20, 10, 18,  9,\n",
      "       32, 32, 33, 11,  0, 35, 36,  6, 18,  2,  3, 13,  5,  8,  0, 17, 15,\n",
      "       26,  6,  4, 25, 19, 27, 19,  0, 24, 19, 30, 29, 25, 19, 31, 24, 31,\n",
      "       23, 27,  3, 10, 17, 29, 13, 16,  7, 23, 24, 32, 30, 20, 18,  9, 18,\n",
      "       10, 15, 17, 12, 14, 24, 31, 37,  4, 27, 19, 15, 33, 11, 23, 36, 16,\n",
      "       28,  7, 12, 22, 21,  3, 12, 13, 17,  4, 31, 20,  5, 20, 30,  7, 35,\n",
      "       12,  1,  0, 35, 19, 23, 18, 37, 12,  9,  8, 25, 32, 26, 19,  2, 22,\n",
      "       32, 10, 36,  3, 37, 14, 23,  8,  7,  9, 18,  9, 18, 12, 19, 30, 30,\n",
      "        4,  6,  5, 37, 10, 18,  2, 12, 27, 17, 27, 18, 13, 12, 24,  7, 17,\n",
      "        9, 14,  3,  2,  6,  3, 20, 25, 23, 35, 36, 19,  8, 33, 15,  1, 17,\n",
      "       22, 21, 29,  4,  9, 33, 23, 22, 32, 25, 17, 30, 35,  0, 22, 29,  2,\n",
      "       33, 36, 24, 22,  9, 31, 33,  8,  1, 11,  9, 30, 30, 36, 11, 20,  6,\n",
      "        4, 13, 25, 16, 24, 17, 23, 35, 13, 27,  5,  3, 30,  9, 27, 22,  1,\n",
      "       20,  0, 29, 37, 17, 31, 15, 18, 13,  1, 37, 11,  4,  8, 37, 19, 36,\n",
      "        2, 16, 27,  3, 13,  0, 27, 12, 31,  2,  6,  7,  2,  0, 20, 30, 16,\n",
      "       34, 30,  0, 27, 15,  5, 25, 15,  1,  1, 13,  1, 12, 33,  9, 34,  9,\n",
      "       30,  6, 25,  9, 10, 30, 18, 14,  0, 10, 11, 19,  1,  3, 22, 20,  2,\n",
      "       14,  0, 11, 32, 10, 20, 19, 12, 12,  8, 32, 17,  2, 29,  6, 18, 13,\n",
      "       21,  0,  1, 11, 12, 32, 15, 26,  9, 15,  3, 36, 13, 15,  8,  4, 21,\n",
      "       25, 30, 25,  2,  9, 27, 31, 25,  0, 15, 22, 13,  2, 13, 19, 33,  0,\n",
      "        8, 19, 27, 36, 13, 29, 11, 16,  0, 14, 25, 10, 18, 15, 10,  1, 26,\n",
      "        9, 21,  5, 14, 37,  7, 12, 30, 26, 11, 17, 31, 22, 33,  6, 16,  0,\n",
      "        1, 34,  1, 14,  0, 10, 35, 13,  7, 22, 31, 37,  3, 18, 20, 32,  2,\n",
      "        9,  9,  1, 10,  4, 30, 10,  6, 22, 26, 37, 11,  5,  1, 25, 28, 15,\n",
      "       10, 19, 18, 32,  0, 37, 26, 25, 27, 18,  5,  1,  0, 13,  8, 35, 26,\n",
      "       30, 35, 21, 10]), array([ 0, 16, 34,  4,  8, 28, 10, 17, 33,  0,  1,  6,  2, 30, 27, 28, 15,\n",
      "       35, 34,  2, 33, 35, 11, 32, 14, 25, 33,  0, 19, 32, 31, 27,  1, 28,\n",
      "        4,  5, 28, 25, 30, 17, 35, 14,  3, 15, 31,  0,  8, 23, 30,  8, 14,\n",
      "       21, 17, 22,  4, 26,  8, 10, 19, 25,  4, 32, 17,  3,  7,  4,  3, 16,\n",
      "       13, 31, 22, 15, 16, 25, 21, 26, 24, 33, 27,  7, 17, 27, 23,  6, 13,\n",
      "       30, 36, 12, 34, 32,  8, 30, 18, 25, 36, 35,  0, 10,  4, 35, 34,  5,\n",
      "       15, 36, 24, 27, 32, 27,  3,  7, 14,  8, 12,  7, 27, 27, 21, 26, 10,\n",
      "       27, 36, 18, 35, 15,  1,  0, 13, 14,  1, 29, 15, 10, 17, 13, 24, 12,\n",
      "       30, 29, 29, 10, 34, 25, 12, 35, 10, 18, 12, 16, 32, 18, 36, 29,  3,\n",
      "       29, 18,  0, 27,  4, 12, 23, 23, 31,  2, 27,  3, 35, 29, 20, 36, 31,\n",
      "        6, 12,  1, 16,  6, 29, 25, 30,  8, 10, 10,  9,  2, 30, 10, 32,  9,\n",
      "       29, 18, 13, 19, 11, 36, 10, 33, 13,  2, 18, 18,  4, 28,  1, 15, 26,\n",
      "       14, 18, 16, 32, 21, 15,  0, 18,  0,  7, 15, 15, 13, 14, 33, 37, 10,\n",
      "       13, 28, 15, 10,  7, 20,  1, 22,  8, 21,  4, 30, 13,  9, 13,  3, 32,\n",
      "       14, 24, 23, 18,  1, 33,  5, 18,  9, 34, 29,  7,  1, 29,  7, 25,  4,\n",
      "       32, 13,  0,  4,  1, 10,  1,  6,  9, 29,  5,  6,  0, 26, 10, 18,  2,\n",
      "       32, 32, 33,  7,  0, 12, 36,  7,  0, 25, 26, 13,  5,  8,  0, 17, 15,\n",
      "       26,  8,  4, 25, 19, 34, 19,  0, 24, 19, 16,  8, 25, 19, 35, 24, 33,\n",
      "       23, 27,  3, 10, 17, 29, 17, 16,  7, 23, 24, 32, 30,  6, 18,  9, 18,\n",
      "       10, 15, 17, 24, 34, 23, 31,  3,  4, 27, 19, 15, 33, 11, 23, 36, 16,\n",
      "       28,  7, 31, 22, 36,  3, 12, 13, 17,  4, 31, 34,  5, 20, 30,  7, 12,\n",
      "       12,  1, 36, 35, 19, 23, 18, 37, 12,  4, 11, 25, 32, 26, 19, 25, 22,\n",
      "       32, 15, 36,  3,  3, 29,  1,  8,  7,  9, 18,  9, 18, 12, 19, 30, 30,\n",
      "        4, 14,  5,  3, 29, 18, 21, 12, 34,  4, 27, 18, 13, 12, 18,  7, 27,\n",
      "        9, 14,  3,  7,  6,  3, 23, 25, 23, 35, 36, 19,  8, 33, 15,  1, 17,\n",
      "       22, 21, 29,  4,  9, 10, 23, 22, 29, 25, 17, 30, 35,  0, 22, 29,  2,\n",
      "       35,  7, 24, 22,  9, 31, 33,  8,  1, 11,  8, 35, 30, 36, 11, 23,  6,\n",
      "        4, 13, 25, 16, 24, 17, 23, 28, 13, 27, 18,  3, 30,  9, 27, 22, 18,\n",
      "       20,  0, 34, 37, 17, 31, 15, 18, 17,  1, 37, 11, 17, 27, 37, 19, 36,\n",
      "        2, 16, 27, 23, 13,  0, 27, 12, 33,  2,  6,  7,  2,  0, 34, 30, 16,\n",
      "        8, 30,  0, 27, 15,  5, 25, 15,  1,  1, 13, 20, 12, 33, 37, 14, 30,\n",
      "       30,  8, 25,  9, 10, 30, 18,  6,  0, 10, 11, 19,  1,  8, 22, 23,  2,\n",
      "       14,  0,  9, 32, 10, 23, 19, 31, 12,  8, 32, 17,  2, 29, 26, 18, 13,\n",
      "       21,  0,  7, 11, 12, 32, 15,  0,  9, 10, 26, 36, 13, 30,  8,  4, 32,\n",
      "       25, 30, 25,  2,  9, 27, 31, 35,  0, 15, 22, 13, 37, 17, 24, 33, 19,\n",
      "        8, 19, 27, 36, 13, 29, 11, 16,  0, 14, 27, 10, 18, 15, 10,  1,  0,\n",
      "        9,  4,  5, 14, 37,  7, 12, 10, 26, 34, 17, 33, 22, 33,  6, 16,  0,\n",
      "        1, 34,  1, 14,  0, 10, 35, 13,  7, 22, 31, 37,  3, 18, 34, 32,  2,\n",
      "        9,  8,  1, 10, 36, 30, 10,  6, 22, 26, 37,  9,  5,  1, 25, 28, 15,\n",
      "       10, 19, 18, 35,  0, 11, 15, 25, 27, 18,  5,  7,  0, 13, 35, 35, 26,\n",
      "       10, 12, 21, 10]), array([ 0, 26, 34,  4,  8, 28, 10, 36, 33,  0,  1,  6,  2, 30, 27, 28, 15,\n",
      "       35, 34,  2, 33, 35, 11, 32, 14, 25, 33,  0, 19, 32, 31, 27,  1, 28,\n",
      "        4,  5, 28, 25, 30, 17, 35, 14,  3,  2, 31,  0,  8, 23, 30,  8, 14,\n",
      "       18, 17, 22,  4, 26,  8, 30, 19, 25,  4, 32, 17,  3,  7,  4,  3, 16,\n",
      "       32, 31, 22, 15, 16, 25, 21, 26, 24, 33, 27,  7, 36, 27, 23, 10, 28,\n",
      "       30, 36, 12, 34, 32,  8, 30, 18, 25, 36, 35,  0, 10,  4, 19, 34,  5,\n",
      "       15, 36, 24, 27, 32, 27,  3,  7, 14,  8, 12, 11, 27, 27, 21, 26, 20,\n",
      "       27, 36, 18, 35, 15,  1, 31, 13, 14, 31, 29, 15, 10, 17, 28, 24, 12,\n",
      "       30, 29, 33, 29, 34, 25, 12, 35, 10, 18, 19, 16, 32, 18, 36, 34,  3,\n",
      "       29, 18,  0, 27,  4, 12, 23, 23, 31,  2, 27,  3, 35, 29, 20, 36, 31,\n",
      "        6, 12,  1, 26,  6, 29, 25, 30,  8, 10, 23,  9,  2, 30, 33, 32,  9,\n",
      "       29, 18, 13, 31, 27, 36, 10, 33, 13,  2, 18, 18,  4, 28,  1, 15, 26,\n",
      "       14, 24, 16, 32, 21, 15,  0, 18,  0,  7, 15, 12, 13, 14, 33, 37, 10,\n",
      "       14, 28, 15, 10,  7, 20,  1, 22,  8, 21,  4, 30, 13,  9, 13,  3, 32,\n",
      "       14, 24, 23, 18,  1, 33,  5, 18,  9, 34, 25,  7,  1, 29,  7, 25,  4,\n",
      "       32, 13,  0,  4,  1, 33,  1,  6,  9, 27, 30,  6,  0, 26, 10, 18,  9,\n",
      "       32, 32, 33, 11,  0, 12, 36,  7,  0, 25, 26, 13,  5,  8,  0, 17, 15,\n",
      "       26,  8,  4, 25, 19, 34, 19,  0, 24, 19, 16, 29, 25, 19, 31, 24, 33,\n",
      "       23, 27,  3, 10, 17, 29, 17, 16,  7, 23, 24, 32, 30,  6, 18,  9, 18,\n",
      "       10, 15, 17, 24, 34, 23, 31,  3,  4, 27, 19, 15, 33, 11, 23, 36, 16,\n",
      "       28,  7, 35, 22, 36,  3, 12, 13, 17,  4, 31, 34,  5, 20, 30,  7, 12,\n",
      "       12,  1, 36, 35, 19, 23, 18, 37, 12,  4, 11, 25, 32, 26, 19, 25, 22,\n",
      "       32, 15, 36,  3,  3, 29,  1,  8,  7,  9, 18,  9, 18, 12, 19, 30, 30,\n",
      "        4, 14,  5,  3,  8, 18, 31, 12, 34,  4, 27, 18, 32, 12, 24,  7, 27,\n",
      "        9, 14,  3, 37,  6,  3, 23, 25, 23, 35, 36, 19,  8, 33, 15,  1, 17,\n",
      "       22, 21, 33,  4,  9, 33, 23, 22, 29, 25, 17, 30, 35,  0, 22, 29,  2,\n",
      "       35,  7, 24, 22,  9, 31, 33,  8, 23, 11,  8, 35, 31, 36, 11, 23,  6,\n",
      "        4, 13, 25, 16, 24, 17, 23, 28, 32, 27, 18,  3, 30,  9, 27, 22, 18,\n",
      "       20,  0, 34, 37, 17, 35, 15, 18, 17,  1, 37, 11, 17, 27, 37, 19, 36,\n",
      "        2, 16, 27, 23, 13,  0, 27, 12, 33,  2,  6,  7,  2,  0, 34, 30, 16,\n",
      "       34, 30,  0, 27, 15,  5, 25, 15,  1,  1, 13, 20, 12, 33, 37, 14, 30,\n",
      "       30,  8,  4,  9, 10, 30, 18,  7,  0, 20, 11, 19,  1,  8, 22, 23,  2,\n",
      "       14,  0,  9, 32, 10, 23, 19, 35, 12,  8, 32, 17,  2, 29, 26, 18, 13,\n",
      "       21,  0,  7, 11, 12, 32, 15,  0,  9, 10, 26, 36, 13, 30,  8,  4, 32,\n",
      "       25, 30, 25,  2,  9, 27, 31, 35,  0, 15, 22, 13, 37, 17, 24, 33, 31,\n",
      "        8, 19, 27, 36, 13, 29, 11, 16,  0, 14, 27, 10, 18, 15, 10,  1,  0,\n",
      "        9,  4,  5, 14, 37,  7, 12, 30, 26, 34, 17, 33, 22, 33,  6, 16,  0,\n",
      "        1, 34,  1, 14,  0, 10, 35, 13,  7, 22, 31, 37,  3, 18, 34, 32,  2,\n",
      "        9,  8,  1, 10, 36, 30, 20,  6, 22, 26, 37,  9,  5,  1, 25, 28, 15,\n",
      "       10, 19, 18, 35,  0, 11, 15, 25, 27, 18,  5,  7,  0, 13, 35, 35, 26,\n",
      "       29, 12, 21, 10]), array([ 0, 26, 34, 34,  8, 28, 10, 17, 33, 18,  1, 28,  2, 30, 27, 28, 15,\n",
      "       35, 34,  2, 33, 35, 11, 32, 22, 25, 33,  0, 19, 32, 31, 27,  1, 28,\n",
      "       29,  5, 28, 25, 30, 17, 35, 14,  3, 15, 31, 18,  8, 23, 30,  8, 14,\n",
      "       18, 17, 22,  4, 26,  8, 30, 19, 25,  4, 32, 17,  3, 13,  4,  3, 16,\n",
      "       13, 31, 22, 15, 16, 25, 21, 26, 24, 33, 27,  7, 17, 27, 23, 10, 28,\n",
      "       30, 36, 12, 34, 32,  8, 11, 18, 25, 36, 35,  0, 10,  4, 19, 34,  5,\n",
      "       15, 36, 24, 27, 32, 27,  3,  7, 14, 37, 12,  7, 27, 27, 21, 26, 20,\n",
      "       27, 36, 18, 35, 15,  1, 31, 13, 14, 31, 29, 15, 10, 17, 28, 24, 12,\n",
      "       30, 29, 29, 29, 34, 25, 12, 35, 10, 18, 19, 16, 32, 18, 36, 34,  3,\n",
      "       29, 18,  0, 27,  4, 12, 23, 23, 31,  2, 27,  3, 35, 29, 20, 36, 31,\n",
      "        6, 23,  1, 26,  6, 29, 25, 30,  8, 28, 23,  9,  2, 30, 33, 32,  9,\n",
      "       29, 18, 13, 31,  4, 36, 10, 33, 13,  2, 19, 18,  8, 28,  1, 15, 26,\n",
      "       14, 35, 16, 32, 21, 15,  0, 18, 23,  7, 15, 15, 13, 14, 33, 37, 10,\n",
      "       14, 28, 15, 10,  7, 20,  1, 22,  8, 21, 29, 30, 13,  9, 13,  3, 32,\n",
      "       14, 24, 23, 18,  1, 33,  5, 18,  9, 34, 34,  7,  1, 29,  7, 25,  4,\n",
      "       32, 13,  0,  8,  1, 33,  1,  6,  9, 10, 30,  6,  0, 26, 10, 18,  2,\n",
      "       32, 32, 33,  7,  0, 12, 36, 15, 18, 25, 26, 13,  5, 37, 23, 17, 15,\n",
      "       26,  8,  4, 25, 19, 34, 19,  0, 24, 19, 16, 29, 25, 19, 31, 24, 33,\n",
      "       23, 27,  3, 10, 17, 29, 17, 16,  7, 23, 24, 32, 30,  6, 18,  9, 18,\n",
      "       10, 15, 17, 31, 14, 24, 31, 37,  4, 27, 19, 15, 33, 11, 23, 36, 16,\n",
      "       28,  7, 31, 22, 36,  3, 12, 13, 17,  4, 31, 34,  5, 20, 30,  7, 12,\n",
      "       12,  1, 36, 35, 19, 23, 18, 37, 12,  4, 11, 25, 32, 26, 19, 25, 22,\n",
      "       32, 18, 36,  3,  3, 29,  1,  8,  7,  9, 18,  9, 18, 12, 19, 30, 30,\n",
      "        4, 14,  5,  3,  8, 18, 16, 12, 34, 34, 27, 18, 13, 12, 35,  7, 27,\n",
      "        9, 14,  3, 37,  6,  3, 23, 25, 23, 35, 36, 19,  8, 33, 15,  1, 17,\n",
      "       22, 28, 29,  4,  9, 33, 23, 22, 29, 25, 17, 30, 35,  0, 22, 29,  2,\n",
      "       35,  7, 24, 22,  9, 31, 33,  8,  1, 11,  8, 35, 31, 36, 11, 23,  6,\n",
      "        4, 13, 25, 16, 24, 17, 23, 28, 13, 27, 18,  3, 30,  9, 27, 22, 19,\n",
      "       20,  0, 34, 37, 17, 35, 15, 18, 17,  1, 37, 11, 17, 27, 37, 19, 36,\n",
      "        2, 16, 27, 23, 13,  0, 27, 12, 33,  2,  6,  7,  2,  0, 34, 30, 16,\n",
      "       34, 30,  0, 27, 15,  5, 25, 15,  1,  1, 13, 20, 23, 33, 37, 20,  9,\n",
      "       30,  8,  4,  9, 10, 30, 18, 14,  0, 20, 11, 19,  1,  8, 22, 23,  2,\n",
      "       14, 16,  9, 32, 10, 23, 19, 31, 12,  8, 32, 17,  2, 29, 31, 18, 13,\n",
      "       21,  0,  7, 11, 12, 32, 15,  0,  9, 10, 26, 36, 13, 30, 37,  4, 32,\n",
      "       25, 30, 25,  2,  9, 27, 31, 35,  0, 15, 22, 13, 37, 17, 24, 33, 31,\n",
      "        8, 19, 27, 36, 13, 29, 11, 16,  0, 14, 27, 10, 18, 15, 10,  1,  0,\n",
      "        9,  4,  5, 14, 37,  7, 12, 30, 26, 34, 17, 33, 22, 33, 28, 16,  0,\n",
      "        1, 34,  1, 14,  0, 10, 35, 13,  7, 22, 31, 37,  3, 18, 34, 32,  2,\n",
      "        9,  8,  1, 10, 36, 30, 20,  6, 22, 26, 37,  9,  5,  1, 25, 28, 15,\n",
      "       10, 19, 18, 35,  0, 11, 15, 25, 27, 18,  5,  7, 23, 13, 35, 35, 26,\n",
      "       29, 12, 21, 10]), array([[ 0],\n",
      "       [16],\n",
      "       [34],\n",
      "       [17],\n",
      "       [ 8],\n",
      "       [28],\n",
      "       [10],\n",
      "       [17],\n",
      "       [33],\n",
      "       [ 0],\n",
      "       [ 1],\n",
      "       [28],\n",
      "       [ 2],\n",
      "       [30],\n",
      "       [27],\n",
      "       [28],\n",
      "       [15],\n",
      "       [35],\n",
      "       [34],\n",
      "       [ 2],\n",
      "       [33],\n",
      "       [35],\n",
      "       [11],\n",
      "       [32],\n",
      "       [36],\n",
      "       [25],\n",
      "       [33],\n",
      "       [ 0],\n",
      "       [19],\n",
      "       [32],\n",
      "       [31],\n",
      "       [27],\n",
      "       [ 1],\n",
      "       [28],\n",
      "       [29],\n",
      "       [ 5],\n",
      "       [28],\n",
      "       [25],\n",
      "       [30],\n",
      "       [17],\n",
      "       [35],\n",
      "       [14],\n",
      "       [ 3],\n",
      "       [15],\n",
      "       [31],\n",
      "       [ 0],\n",
      "       [ 8],\n",
      "       [23],\n",
      "       [30],\n",
      "       [ 8],\n",
      "       [14],\n",
      "       [18],\n",
      "       [17],\n",
      "       [22],\n",
      "       [ 4],\n",
      "       [26],\n",
      "       [ 8],\n",
      "       [30],\n",
      "       [19],\n",
      "       [25],\n",
      "       [ 4],\n",
      "       [32],\n",
      "       [17],\n",
      "       [ 3],\n",
      "       [13],\n",
      "       [ 4],\n",
      "       [ 3],\n",
      "       [16],\n",
      "       [13],\n",
      "       [31],\n",
      "       [22],\n",
      "       [15],\n",
      "       [16],\n",
      "       [25],\n",
      "       [21],\n",
      "       [26],\n",
      "       [24],\n",
      "       [33],\n",
      "       [27],\n",
      "       [ 7],\n",
      "       [17],\n",
      "       [27],\n",
      "       [23],\n",
      "       [10],\n",
      "       [28],\n",
      "       [30],\n",
      "       [36],\n",
      "       [12],\n",
      "       [34],\n",
      "       [32],\n",
      "       [ 8],\n",
      "       [11],\n",
      "       [18],\n",
      "       [25],\n",
      "       [36],\n",
      "       [35],\n",
      "       [ 0],\n",
      "       [10],\n",
      "       [ 4],\n",
      "       [19],\n",
      "       [34],\n",
      "       [ 5],\n",
      "       [15],\n",
      "       [36],\n",
      "       [24],\n",
      "       [27],\n",
      "       [32],\n",
      "       [27],\n",
      "       [ 3],\n",
      "       [ 7],\n",
      "       [14],\n",
      "       [37],\n",
      "       [12],\n",
      "       [ 7],\n",
      "       [27],\n",
      "       [27],\n",
      "       [21],\n",
      "       [26],\n",
      "       [10],\n",
      "       [27],\n",
      "       [13],\n",
      "       [18],\n",
      "       [35],\n",
      "       [15],\n",
      "       [ 1],\n",
      "       [31],\n",
      "       [13],\n",
      "       [14],\n",
      "       [ 4],\n",
      "       [29],\n",
      "       [15],\n",
      "       [18],\n",
      "       [17],\n",
      "       [28],\n",
      "       [24],\n",
      "       [12],\n",
      "       [30],\n",
      "       [29],\n",
      "       [29],\n",
      "       [29],\n",
      "       [34],\n",
      "       [25],\n",
      "       [12],\n",
      "       [35],\n",
      "       [10],\n",
      "       [18],\n",
      "       [19],\n",
      "       [16],\n",
      "       [32],\n",
      "       [18],\n",
      "       [36],\n",
      "       [34],\n",
      "       [ 3],\n",
      "       [29],\n",
      "       [18],\n",
      "       [ 0],\n",
      "       [27],\n",
      "       [ 4],\n",
      "       [12],\n",
      "       [23],\n",
      "       [23],\n",
      "       [31],\n",
      "       [ 2],\n",
      "       [27],\n",
      "       [ 3],\n",
      "       [35],\n",
      "       [29],\n",
      "       [20],\n",
      "       [36],\n",
      "       [31],\n",
      "       [ 6],\n",
      "       [23],\n",
      "       [ 1],\n",
      "       [16],\n",
      "       [ 6],\n",
      "       [29],\n",
      "       [25],\n",
      "       [30],\n",
      "       [ 8],\n",
      "       [10],\n",
      "       [10],\n",
      "       [ 9],\n",
      "       [ 2],\n",
      "       [30],\n",
      "       [33],\n",
      "       [32],\n",
      "       [ 9],\n",
      "       [29],\n",
      "       [18],\n",
      "       [13],\n",
      "       [31],\n",
      "       [11],\n",
      "       [36],\n",
      "       [10],\n",
      "       [33],\n",
      "       [13],\n",
      "       [ 2],\n",
      "       [19],\n",
      "       [18],\n",
      "       [ 8],\n",
      "       [28],\n",
      "       [ 1],\n",
      "       [15],\n",
      "       [26],\n",
      "       [14],\n",
      "       [24],\n",
      "       [16],\n",
      "       [32],\n",
      "       [21],\n",
      "       [15],\n",
      "       [ 0],\n",
      "       [18],\n",
      "       [23],\n",
      "       [ 7],\n",
      "       [15],\n",
      "       [15],\n",
      "       [13],\n",
      "       [14],\n",
      "       [33],\n",
      "       [37],\n",
      "       [10],\n",
      "       [14],\n",
      "       [28],\n",
      "       [15],\n",
      "       [10],\n",
      "       [ 7],\n",
      "       [20],\n",
      "       [ 1],\n",
      "       [22],\n",
      "       [ 8],\n",
      "       [21],\n",
      "       [29],\n",
      "       [30],\n",
      "       [13],\n",
      "       [ 9],\n",
      "       [13],\n",
      "       [ 3],\n",
      "       [32],\n",
      "       [14],\n",
      "       [24],\n",
      "       [23],\n",
      "       [18],\n",
      "       [ 1],\n",
      "       [33],\n",
      "       [ 5],\n",
      "       [18],\n",
      "       [ 9],\n",
      "       [34],\n",
      "       [15],\n",
      "       [ 7],\n",
      "       [ 1],\n",
      "       [29],\n",
      "       [ 7],\n",
      "       [25],\n",
      "       [ 4],\n",
      "       [32],\n",
      "       [13],\n",
      "       [ 0],\n",
      "       [ 8],\n",
      "       [ 1],\n",
      "       [33],\n",
      "       [ 1],\n",
      "       [ 6],\n",
      "       [ 9],\n",
      "       [10],\n",
      "       [30],\n",
      "       [ 6],\n",
      "       [ 0],\n",
      "       [26],\n",
      "       [10],\n",
      "       [18],\n",
      "       [ 2],\n",
      "       [32],\n",
      "       [32],\n",
      "       [33],\n",
      "       [ 7],\n",
      "       [ 0],\n",
      "       [12],\n",
      "       [ 4],\n",
      "       [ 7],\n",
      "       [ 0],\n",
      "       [25],\n",
      "       [26],\n",
      "       [13],\n",
      "       [ 5],\n",
      "       [37],\n",
      "       [23],\n",
      "       [17],\n",
      "       [15],\n",
      "       [26],\n",
      "       [ 8],\n",
      "       [ 4],\n",
      "       [25],\n",
      "       [19],\n",
      "       [34],\n",
      "       [19],\n",
      "       [ 0],\n",
      "       [24],\n",
      "       [19],\n",
      "       [16],\n",
      "       [29],\n",
      "       [25],\n",
      "       [19],\n",
      "       [31],\n",
      "       [24],\n",
      "       [33],\n",
      "       [23],\n",
      "       [27],\n",
      "       [ 3],\n",
      "       [10],\n",
      "       [17],\n",
      "       [29],\n",
      "       [17],\n",
      "       [16],\n",
      "       [ 7],\n",
      "       [23],\n",
      "       [24],\n",
      "       [32],\n",
      "       [30],\n",
      "       [20],\n",
      "       [18],\n",
      "       [ 9],\n",
      "       [18],\n",
      "       [10],\n",
      "       [15],\n",
      "       [17],\n",
      "       [31],\n",
      "       [14],\n",
      "       [24],\n",
      "       [31],\n",
      "       [ 3],\n",
      "       [ 4],\n",
      "       [27],\n",
      "       [19],\n",
      "       [15],\n",
      "       [33],\n",
      "       [11],\n",
      "       [23],\n",
      "       [36],\n",
      "       [16],\n",
      "       [28],\n",
      "       [ 7],\n",
      "       [31],\n",
      "       [22],\n",
      "       [36],\n",
      "       [ 3],\n",
      "       [12],\n",
      "       [13],\n",
      "       [17],\n",
      "       [ 4],\n",
      "       [31],\n",
      "       [34],\n",
      "       [ 5],\n",
      "       [20],\n",
      "       [30],\n",
      "       [ 7],\n",
      "       [12],\n",
      "       [12],\n",
      "       [ 1],\n",
      "       [13],\n",
      "       [35],\n",
      "       [19],\n",
      "       [23],\n",
      "       [18],\n",
      "       [37],\n",
      "       [12],\n",
      "       [ 4],\n",
      "       [11],\n",
      "       [25],\n",
      "       [32],\n",
      "       [26],\n",
      "       [19],\n",
      "       [25],\n",
      "       [22],\n",
      "       [32],\n",
      "       [15],\n",
      "       [36],\n",
      "       [ 3],\n",
      "       [ 3],\n",
      "       [29],\n",
      "       [ 1],\n",
      "       [ 8],\n",
      "       [ 7],\n",
      "       [ 9],\n",
      "       [18],\n",
      "       [ 9],\n",
      "       [18],\n",
      "       [12],\n",
      "       [19],\n",
      "       [30],\n",
      "       [30],\n",
      "       [ 4],\n",
      "       [14],\n",
      "       [ 5],\n",
      "       [ 3],\n",
      "       [ 8],\n",
      "       [18],\n",
      "       [31],\n",
      "       [12],\n",
      "       [34],\n",
      "       [17],\n",
      "       [27],\n",
      "       [18],\n",
      "       [13],\n",
      "       [12],\n",
      "       [24],\n",
      "       [ 7],\n",
      "       [27],\n",
      "       [ 9],\n",
      "       [14],\n",
      "       [ 3],\n",
      "       [37],\n",
      "       [ 6],\n",
      "       [ 3],\n",
      "       [23],\n",
      "       [25],\n",
      "       [23],\n",
      "       [35],\n",
      "       [36],\n",
      "       [19],\n",
      "       [ 8],\n",
      "       [33],\n",
      "       [15],\n",
      "       [ 1],\n",
      "       [17],\n",
      "       [22],\n",
      "       [21],\n",
      "       [29],\n",
      "       [ 4],\n",
      "       [ 9],\n",
      "       [33],\n",
      "       [23],\n",
      "       [22],\n",
      "       [29],\n",
      "       [25],\n",
      "       [17],\n",
      "       [30],\n",
      "       [35],\n",
      "       [ 0],\n",
      "       [22],\n",
      "       [29],\n",
      "       [ 2],\n",
      "       [35],\n",
      "       [ 7],\n",
      "       [24],\n",
      "       [22],\n",
      "       [ 9],\n",
      "       [31],\n",
      "       [33],\n",
      "       [ 8],\n",
      "       [23],\n",
      "       [11],\n",
      "       [ 8],\n",
      "       [35],\n",
      "       [31],\n",
      "       [36],\n",
      "       [11],\n",
      "       [23],\n",
      "       [ 6],\n",
      "       [ 4],\n",
      "       [13],\n",
      "       [25],\n",
      "       [16],\n",
      "       [24],\n",
      "       [17],\n",
      "       [23],\n",
      "       [28],\n",
      "       [13],\n",
      "       [27],\n",
      "       [18],\n",
      "       [ 3],\n",
      "       [30],\n",
      "       [ 9],\n",
      "       [27],\n",
      "       [22],\n",
      "       [19],\n",
      "       [20],\n",
      "       [ 0],\n",
      "       [34],\n",
      "       [37],\n",
      "       [17],\n",
      "       [35],\n",
      "       [15],\n",
      "       [18],\n",
      "       [17],\n",
      "       [ 1],\n",
      "       [37],\n",
      "       [11],\n",
      "       [17],\n",
      "       [27],\n",
      "       [37],\n",
      "       [19],\n",
      "       [36],\n",
      "       [ 2],\n",
      "       [16],\n",
      "       [27],\n",
      "       [23],\n",
      "       [13],\n",
      "       [ 0],\n",
      "       [27],\n",
      "       [12],\n",
      "       [33],\n",
      "       [ 2],\n",
      "       [ 6],\n",
      "       [ 7],\n",
      "       [ 2],\n",
      "       [ 0],\n",
      "       [34],\n",
      "       [30],\n",
      "       [16],\n",
      "       [34],\n",
      "       [30],\n",
      "       [ 0],\n",
      "       [27],\n",
      "       [15],\n",
      "       [ 5],\n",
      "       [25],\n",
      "       [15],\n",
      "       [ 1],\n",
      "       [ 1],\n",
      "       [13],\n",
      "       [20],\n",
      "       [23],\n",
      "       [33],\n",
      "       [37],\n",
      "       [14],\n",
      "       [30],\n",
      "       [30],\n",
      "       [ 8],\n",
      "       [25],\n",
      "       [ 9],\n",
      "       [10],\n",
      "       [30],\n",
      "       [18],\n",
      "       [14],\n",
      "       [ 0],\n",
      "       [10],\n",
      "       [11],\n",
      "       [19],\n",
      "       [ 1],\n",
      "       [ 8],\n",
      "       [22],\n",
      "       [23],\n",
      "       [ 2],\n",
      "       [14],\n",
      "       [ 0],\n",
      "       [ 9],\n",
      "       [32],\n",
      "       [10],\n",
      "       [23],\n",
      "       [19],\n",
      "       [31],\n",
      "       [12],\n",
      "       [ 8],\n",
      "       [32],\n",
      "       [17],\n",
      "       [ 2],\n",
      "       [29],\n",
      "       [31],\n",
      "       [18],\n",
      "       [13],\n",
      "       [21],\n",
      "       [ 0],\n",
      "       [ 7],\n",
      "       [11],\n",
      "       [12],\n",
      "       [32],\n",
      "       [15],\n",
      "       [ 0],\n",
      "       [ 9],\n",
      "       [10],\n",
      "       [26],\n",
      "       [36],\n",
      "       [13],\n",
      "       [30],\n",
      "       [37],\n",
      "       [ 4],\n",
      "       [32],\n",
      "       [25],\n",
      "       [30],\n",
      "       [25],\n",
      "       [ 2],\n",
      "       [ 9],\n",
      "       [27],\n",
      "       [31],\n",
      "       [35],\n",
      "       [ 0],\n",
      "       [15],\n",
      "       [22],\n",
      "       [13],\n",
      "       [37],\n",
      "       [17],\n",
      "       [24],\n",
      "       [33],\n",
      "       [31],\n",
      "       [ 8],\n",
      "       [19],\n",
      "       [27],\n",
      "       [36],\n",
      "       [13],\n",
      "       [29],\n",
      "       [11],\n",
      "       [16],\n",
      "       [ 0],\n",
      "       [14],\n",
      "       [27],\n",
      "       [10],\n",
      "       [18],\n",
      "       [15],\n",
      "       [10],\n",
      "       [ 1],\n",
      "       [ 0],\n",
      "       [ 9],\n",
      "       [ 4],\n",
      "       [ 5],\n",
      "       [14],\n",
      "       [37],\n",
      "       [ 7],\n",
      "       [12],\n",
      "       [30],\n",
      "       [26],\n",
      "       [11],\n",
      "       [17],\n",
      "       [33],\n",
      "       [22],\n",
      "       [33],\n",
      "       [28],\n",
      "       [16],\n",
      "       [ 0],\n",
      "       [ 1],\n",
      "       [34],\n",
      "       [ 1],\n",
      "       [14],\n",
      "       [ 0],\n",
      "       [10],\n",
      "       [35],\n",
      "       [13],\n",
      "       [ 7],\n",
      "       [22],\n",
      "       [31],\n",
      "       [37],\n",
      "       [ 3],\n",
      "       [18],\n",
      "       [34],\n",
      "       [32],\n",
      "       [ 2],\n",
      "       [ 9],\n",
      "       [ 8],\n",
      "       [ 1],\n",
      "       [10],\n",
      "       [36],\n",
      "       [30],\n",
      "       [10],\n",
      "       [ 6],\n",
      "       [22],\n",
      "       [26],\n",
      "       [37],\n",
      "       [ 9],\n",
      "       [ 5],\n",
      "       [ 1],\n",
      "       [25],\n",
      "       [28],\n",
      "       [15],\n",
      "       [10],\n",
      "       [19],\n",
      "       [18],\n",
      "       [35],\n",
      "       [ 0],\n",
      "       [11],\n",
      "       [15],\n",
      "       [25],\n",
      "       [27],\n",
      "       [18],\n",
      "       [ 5],\n",
      "       [ 7],\n",
      "       [23],\n",
      "       [13],\n",
      "       [35],\n",
      "       [35],\n",
      "       [26],\n",
      "       [29],\n",
      "       [12],\n",
      "       [21],\n",
      "       [10]]), array([15, 29, 37,  6, 13, 29, 29,  6,  3, 22, 29, 15, 37, 35, 25, 29, 29,\n",
      "       15,  6, 37, 29, 15, 11,  6, 25,  9,  3,  3, 19,  6,  9,  6, 29, 29,\n",
      "       13, 25, 15, 25, 36, 35, 29,  6, 29,  3,  9, 22, 11, 15, 11, 36, 19,\n",
      "       13,  6, 11, 25,  3,  6, 15, 35,  9,  6, 19,  6, 29, 20, 25, 29, 13,\n",
      "       19, 15, 11, 29, 37, 25,  6,  3, 35,  9, 25, 35,  6, 11, 13, 15,  6,\n",
      "        9, 29, 15,  6,  6, 29, 36, 25, 25, 36, 25, 29, 29, 25, 35, 25, 36,\n",
      "       15, 29,  3, 25,  6, 13,  3, 37, 19,  9, 11, 11, 25, 29, 13, 22,  6,\n",
      "       25, 36, 25, 19, 15, 29, 29, 19, 19, 29, 25, 15, 13,  6,  6,  3,  3,\n",
      "       29, 33, 29, 29,  6, 25, 29, 29, 29,  9, 15, 13,  6, 22, 29,  6, 29,\n",
      "       25, 29,  3, 25, 25, 15, 29, 29, 35,  3, 25, 29,  3, 25,  6, 25,  3,\n",
      "        6,  3, 33, 29, 29, 29, 35,  3,  6, 15, 15, 29,  3, 11, 15, 19,  9,\n",
      "       29,  9, 19, 15,  6, 25, 29, 15, 19, 33, 29, 15, 25, 29, 15, 33, 15,\n",
      "        6, 15, 19,  6, 29, 15, 25, 15, 29, 37, 15,  3,  6, 19, 15, 11, 29,\n",
      "       19, 29,  3, 13, 35,  6, 29, 11, 13, 13, 13, 25,  6,  3, 36, 29, 19,\n",
      "       20,  3, 20, 22, 29, 29, 36, 25,  9, 29, 25, 37, 29, 29,  9,  6,  6,\n",
      "        6, 35,  3, 25, 29, 15, 29,  6, 25,  6,  9, 11,  3, 29, 29, 22,  9,\n",
      "        6,  6, 29, 11,  3,  3, 25,  6, 22,  3,  3, 19, 36,  9, 29,  6, 15,\n",
      "       15,  6, 25,  9, 35, 25, 19, 19,  3, 35, 13, 29, 25, 19,  3,  3,  9,\n",
      "       29, 25,  9, 29,  6, 29,  6, 13, 37, 29,  3,  6, 25,  6, 15,  3,  9,\n",
      "       29, 15,  6,  3, 37,  3,  9,  9, 25, 13, 35, 15, 29, 25, 29, 25, 13,\n",
      "        6, 13, 15,  6, 36,  9, 29, 35, 35, 36,  3,  6, 25,  6, 36, 20,  3,\n",
      "       15, 19, 36, 28, 35, 13,  9, 37, 15, 29, 25,  9, 11, 22, 29,  3,  6,\n",
      "        6, 15, 25, 13, 29,  3, 29, 13, 37, 29, 25,  9, 29, 15, 15, 36, 15,\n",
      "       25, 11, 25, 29,  6, 15, 13, 15, 25,  6, 13,  9, 19, 15, 15, 37, 25,\n",
      "        3,  6, 25, 37, 11,  3, 29, 25, 13,  6, 36, 35, 35, 29, 15, 29,  6,\n",
      "       11, 29, 29, 25,  3, 15, 29, 11, 28, 25,  6,  9, 15, 33,  6, 29, 33,\n",
      "       29, 35,  3, 11, 29,  3, 33, 35, 29, 25, 13, 25,  3, 25,  3, 29,  6,\n",
      "       19, 36, 29, 13, 36, 35, 15, 29, 19, 13, 36, 29,  6,  3, 25, 36, 29,\n",
      "        6, 19, 25, 11,  6, 33, 15, 15,  6,  6, 37,  9,  6, 25, 11, 35, 36,\n",
      "        9, 13, 29, 29, 36, 25, 13, 15,  9, 33,  6, 37, 37,  3,  6, 15, 13,\n",
      "        6, 25,  3,  6, 29, 29, 25, 33, 33, 33,  6, 13,  3,  6, 37,  6, 25,\n",
      "       36,  6, 29,  9, 29,  9, 22, 11, 29,  6,  9, 19, 29,  9, 11, 29, 37,\n",
      "        6,  3,  3,  6, 15, 29, 35, 15, 15,  6, 19,  6, 33, 29, 15, 22, 13,\n",
      "       36,  3, 19, 29, 20,  6, 29,  3,  9, 29,  3, 36,  6,  9,  9, 36, 13,\n",
      "       25,  9, 25, 25, 15, 25,  3, 25,  3, 33, 11,  6, 37,  6, 35, 33, 15,\n",
      "       29, 29, 13, 36, 19, 25, 25, 13,  3, 19, 25, 15, 22, 29, 29, 29,  3,\n",
      "        9, 13, 15, 19, 37, 13, 29, 15, 15, 25, 25,  9, 36, 15, 15, 13, 19,\n",
      "       33,  6, 33, 19,  3, 29, 15, 36,  9, 13,  3, 37, 29, 22,  6, 19, 25,\n",
      "        9, 13, 29, 29, 25, 36,  6, 11, 11, 15, 37,  3, 25, 29, 25,  6, 29,\n",
      "       15, 35, 29, 35,  3,  6, 15, 25, 25, 29, 29, 19, 29, 19,  6, 35,  3,\n",
      "       29,  3, 15, 29])]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"K-Neighbors classifier\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest classifier\": RandomForestClassifier(),\n",
    "    \"XGBclassifier\": XGBClassifier(), \n",
    "    \"CatBoosting classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost classifier\": AdaBoostClassifier()\n",
    "}\n",
    "model_list = []\n",
    "tr_acc =[]\n",
    "te_acc=[]\n",
    "l=[]\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_samp_train, y_samp_train) # Train model\n",
    "\n",
    "    # Make predictions\n",
    "    y_samp_train_pred = model.predict(X_samp_train)\n",
    "    y_samp_test_pred = model.predict(X_samp_test)\n",
    "    l.append(y_samp_test_pred)\n",
    "    # Evaluate Train and Test dataset\n",
    "    model_samp_train_acc = evaluate_model(y_samp_train, y_samp_train_pred)\n",
    "\n",
    "    model_samp_test_acc = evaluate_model(y_samp_test, y_samp_test_pred)\n",
    "\n",
    "    \n",
    "    print(list(models.keys())[i])\n",
    "    model_list.append(list(models.keys())[i])\n",
    "    \n",
    "    print('Model performance for Training set')\n",
    "    print(\"- Accuracy score for train data: {:.4f}\".format(model_samp_train_acc))\n",
    "  \n",
    "    print('----------------------------------')\n",
    "    \n",
    "    print('Model performance for Test set')\n",
    "    print(\"- Accuracy score for train data: {:.4f}\".format(model_samp_test_acc))\n",
    "\n",
    "    tr_acc.append(model_samp_train_acc)\n",
    "    te_acc.append(model_samp_test_acc)\n",
    "    \n",
    "    print('='*35)\n",
    "    print('\\n')\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9b1595f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>TR_ACC</th>\n",
       "      <th>TE_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBclassifier</td>\n",
       "      <td>0.706140</td>\n",
       "      <td>0.539474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoosting classifier</td>\n",
       "      <td>0.706506</td>\n",
       "      <td>0.533626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.706506</td>\n",
       "      <td>0.530702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.706506</td>\n",
       "      <td>0.521930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Neighbors classifier</td>\n",
       "      <td>0.621711</td>\n",
       "      <td>0.466374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost classifier</td>\n",
       "      <td>0.106360</td>\n",
       "      <td>0.093567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Name    TR_ACC    TE_ACC\n",
       "3             XGBclassifier  0.706140  0.539474\n",
       "4    CatBoosting classifier  0.706506  0.533626\n",
       "2  Random Forest classifier  0.706506  0.530702\n",
       "1             Decision Tree  0.706506  0.521930\n",
       "0    K-Neighbors classifier  0.621711  0.466374\n",
       "5       AdaBoost classifier  0.106360  0.093567"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(zip(model_list,tr_acc,te_acc)), columns=['Model Name','TR_ACC','TE_ACC']).sort_values(by=[\"TE_ACC\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9aa5cb",
   "metadata": {},
   "source": [
    "so for balanced dataset the training and testing accuracy have been increased....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4839e1a8",
   "metadata": {},
   "source": [
    "Combining Predictions for Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f3812dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 53.22%\n"
     ]
    }
   ],
   "source": [
    "from statistics import mode\n",
    "\n",
    "final_preds = [mode([i.item(), j.item(), k.item(), m.item(), n.item(), o.item()])  for i, j, k, m, n, o in zip(*l)]\n",
    "\n",
    "print(f\"Combined Model Accuracy: {accuracy_score(y_samp_test, final_preds) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a7fb6",
   "metadata": {},
   "source": [
    "✅ Working Version:\n",
    "If l is a list of 6 arrays (each same length) and each element is an int:\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "final_preds = [mode([i, j, k, m, n, o]) for i, j, k, m, n, o in zip(*l)]\n",
    "print(final_preds)\n",
    "\n",
    "got hashtype error so tried this  :\n",
    "\n",
    "\n",
    "You need to extract scalar values:\n",
    "\n",
    "final_preds = [mode([i.item(), j.item(), k.item(), m.item(), n.item(), o.item()]) \n",
    "               for i, j, k, m, n, o in zip(*l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4843bb1b",
   "metadata": {},
   "source": [
    "Train each model individually and build the Robust model by combining them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5e6c734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Model Accuracy: 53.07%\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_model=knn.fit(X_samp_train, y_samp_train)\n",
    "knn_preds = knn_model.predict(X_samp_test)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_model=dt.fit(X_samp_train, y_samp_train)\n",
    "dt_preds = dt_model.predict(X_samp_test)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model=rf.fit(X_samp_train, y_samp_train)\n",
    "rf_preds = rf_model.predict(X_samp_test)\n",
    "\n",
    "\n",
    "from statistics import mode\n",
    "\n",
    "final_preds = [mode([i, j, k]) for i, j, k in zip(knn_preds, dt_preds, rf_preds)]\n",
    "\n",
    "print(f\"Combined Model Accuracy: {accuracy_score(y_samp_test, final_preds) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eca9d8",
   "metadata": {},
   "source": [
    "Test the model giving some input value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9621885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Random Forest Prediction': 'Hypoglycemia', 'knn Prediction': 'Hypoglycemia', 'dt Prediction': 'Hypoglycemia', 'Final Prediction': 'Hypoglycemia'}\n"
     ]
    }
   ],
   "source": [
    "symptoms = X.columns.values\n",
    "symptom_index = {symptom: idx for idx, symptom in enumerate(symptoms)}\n",
    "\n",
    "def predict_disease(input_symptoms):\n",
    "    input_symptoms = input_symptoms.split(\",\")\n",
    "    input_data = [0] * len(symptom_index)\n",
    "    \n",
    "    for symptom in input_symptoms:\n",
    "        if symptom in symptom_index:\n",
    "            input_data[symptom_index[symptom]] = 1\n",
    "    \n",
    "    input_data = np.array(input_data).reshape(1, -1)\n",
    "\n",
    "    rf_pred = le.classes_[rf_model.predict(input_data)[0]]\n",
    "    knn_pred = le.classes_[knn_model.predict(input_data)[0]]\n",
    "    dt_pred = le.classes_[dt_model.predict(input_data)[0]]\n",
    "\n",
    "    final_pred = mode([rf_pred, knn_pred, dt_pred])\n",
    "    \n",
    "    return {\n",
    "        \"Random Forest Prediction\": rf_pred,\n",
    "        \"knn Prediction\": knn_pred,\n",
    "        \"dt Prediction\": dt_pred,\n",
    "        \"Final Prediction\": final_pred\n",
    "    }\n",
    "\n",
    "\n",
    "# Test\n",
    "print(predict_disease(\"fever,headache,yellow_eyes\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
